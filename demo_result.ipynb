{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='BARRA_R and ACCESS-S!')\n",
    "parser.add_argument('--prprpr', action='store_true',\n",
    "                    help='Enables debug mode')\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help='Enables debug mode')\n",
    "parser.add_argument('--template', default='.',\n",
    "                    help='You can set various templates in option.py')\n",
    "\n",
    "# Hardware specifications\n",
    "parser.add_argument('--n_threads', type=int, default=0,\n",
    "                    help='number of threads for data loading')\n",
    "parser.add_argument('--cpu', action='store_true',\n",
    "                    help='use cpu only')\n",
    "parser.add_argument('--n_GPUs', type=int, default=1,\n",
    "                    help='number of GPUs')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed')\n",
    "\n",
    "# Data specifications\n",
    "\n",
    "parser.add_argument('--pr', type=bool, \n",
    "                default=True,\n",
    "                help='add-on pr?')\n",
    "\n",
    "parser.add_argument('--dem', action='store_true',\n",
    "                help='add-on dem?') \n",
    "parser.add_argument('--psl', action='store_true',\n",
    "                help='add-on psl?') \n",
    "parser.add_argument('--zg', action='store_true',\n",
    "                help='add-on zg?') \n",
    "parser.add_argument('--tasmax', action='store_true',\n",
    "                help='add-on tasmax?') \n",
    "parser.add_argument('--tasmin', action='store_true',\n",
    "                help='add-on tasmin?')\n",
    "\n",
    "# parser.add_argument('--pr', type=bool, \n",
    "#                 default=True,\n",
    "#                 help='add-on pr?')\n",
    "\n",
    "# parser.add_argument('--dem', type=bool, \n",
    "#                 default=False,\n",
    "#                 help='add-on dem?') \n",
    "# parser.add_argument('--psl', type=bool, \n",
    "#                 default=False,\n",
    "#                 help='add-on psl?') \n",
    "# parser.add_argument('--zg', type=bool, \n",
    "#                 default=False,\n",
    "#                 help='add-on zg?') \n",
    "# parser.add_argument('--tasmax', type=bool, \n",
    "#                 default=False,\n",
    "#                 help='add-on tasmax?') \n",
    "# parser.add_argument('--tasmin', type=bool, \n",
    "#                 default=False,\n",
    "#                 help='add-on tasmin?')\n",
    "\n",
    "parser.add_argument('--leading_time_we_use', type=int, \n",
    "                default=7,\n",
    "                help='add-on tasmin?')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument('--ensemble', type=int, \n",
    "                default=2,\n",
    "                help='total ensambles is 11') \n",
    "\n",
    "\n",
    "parser.add_argument('--channels', type=float, \n",
    "                    default=0,\n",
    "                    help='channel of data_input must') \n",
    "#[111.85, 155.875, -44.35, -9.975]\n",
    "parser.add_argument('--domain', type=list, \n",
    "                    default=[112.9, 154.25, -43.7425, -9.0],\n",
    "                    help='dataset directory')    \n",
    "\n",
    "\n",
    "parser.add_argument('--file_ACCESS_dir', type=str, \n",
    "                    default=\"../data/\",\n",
    "\n",
    "                    help='dataset directory')\n",
    "parser.add_argument('--file_BARRA_dir', type=str, \n",
    "                    default=\"../data/barra_aus/\",\n",
    "                    help='dataset directory')\n",
    "\n",
    "parser.add_argument('--file_DEM_dir', type=str, \n",
    "                    default=\"../DEM/\",\n",
    "                    help='dataset directory')\n",
    "\n",
    "parser.add_argument('--nine2nine', type=bool, \n",
    "                    default=True,\n",
    "                    help='whether rainfall acculate from 9am to 9am')\n",
    "parser.add_argument('--date_minus_one', type=int, \n",
    "                    default=1,\n",
    "                    help='whether rainfall acculate from yesterday(1)/today(0) 9am to tody/tomorrow 9am')\n",
    "\n",
    "\n",
    "parser.add_argument('--dir_demo', type=str, default='../test',\n",
    "                    help='demo image directory')\n",
    "#     parser.add_argument('--data_train', type=str, default='BARRA_R',\n",
    "#                         help='train dataset name')\n",
    "#     parser.add_argument('--data_test', type=str, default='DIV2K',\n",
    "#                         help='test dataset name')\n",
    "parser.add_argument('--benchmark_noise', action='store_true',\n",
    "                    help='use noisy benchmark sets')\n",
    "parser.add_argument('--n_train', type=int, default=800,\n",
    "                    help='number of training set')\n",
    "parser.add_argument('--n_val', type=int, default=10,\n",
    "                    help='number of validation set')\n",
    "parser.add_argument('--offset_val', type=int, default=800,\n",
    "                    help='validation index offest')\n",
    "parser.add_argument('--ext', type=str, default='sep',\n",
    "                    help='dataset file extension')\n",
    "parser.add_argument('--scale', default='4',\n",
    "                    help='super resolution scale')\n",
    "parser.add_argument('--patch_size', type=int, default=192,\n",
    "                    help='output patch size')\n",
    "#??????????????????????????????????????????????????\n",
    "parser.add_argument('--rgb_range', type=int, default=255,\n",
    "                    help='maximum value of RGB')\n",
    "parser.add_argument('--n_colors', type=int, default=1,\n",
    "                    help='number of color channels to use')\n",
    "parser.add_argument('--noise', type=str, default='.',\n",
    "                    help='Gaussian noise std.')\n",
    "parser.add_argument('--chop', action='store_true',\n",
    "                    help='enable memory-efficient forward')\n",
    "\n",
    "# Model specifications\n",
    "parser.add_argument('--model', default='RCAN',\n",
    "                    help='model name')\n",
    "\n",
    "parser.add_argument('--act', type=str, default='relu',\n",
    "                    help='activation function')\n",
    "parser.add_argument('--continue_train', type=str, default='.',\n",
    "                    help='pre-trained model directory')\n",
    "\n",
    "parser.add_argument('--pre_train', type=str, default='.',\n",
    "                    help='pre-trained model directory')\n",
    "parser.add_argument('--extend', type=str, default='.',\n",
    "                    help='pre-trained model directory')\n",
    "parser.add_argument('--n_resblocks', type=int, default=20,\n",
    "                    help='number of residual blocks')\n",
    "parser.add_argument('--n_feats', type=int, default=64,\n",
    "                    help='number of feature maps')\n",
    "parser.add_argument('--res_scale', type=float, default=1,\n",
    "                    help='residual scaling')\n",
    "parser.add_argument('--shift_mean', default=True,\n",
    "                    help='subtract pixel mean from the input')\n",
    "parser.add_argument('--precision', type=str, default='single',\n",
    "                    choices=('single', 'half','double'),\n",
    "                    help='FP precision for test (single | half)')\n",
    "\n",
    "# Training specifications\n",
    "\n",
    "parser.add_argument('--train_name', type=str, default='temp01',\n",
    "                    help='the trainning name of the set')\n",
    "parser.add_argument('--reset', action='store_true',\n",
    "                    help='reset the training')\n",
    "parser.add_argument('--test_every', type=int, default=1000,\n",
    "                    help='do test per every N batches')\n",
    "parser.add_argument('--epochs', type=int, default=300,\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                    help='input batch size for training')\n",
    "parser.add_argument('--split_batch', type=int, default=1,\n",
    "                    help='split the batch into smaller chunks')\n",
    "parser.add_argument('--self_ensemble', action='store_true',\n",
    "                    help='use self-ensemble method for test')\n",
    "parser.add_argument('--test_only', action='store_true',\n",
    "                    help='set this option to test the model')\n",
    "parser.add_argument('--gan_k', type=int, default=1,\n",
    "                    help='k value for adversarial loss')\n",
    "\n",
    "# Optimization specifications\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay', type=int, default=200,\n",
    "                    help='learning rate decay per N epochs')\n",
    "parser.add_argument('--decay_type', type=str, default='step',\n",
    "                    help='learning rate decay type')\n",
    "parser.add_argument('--gamma', type=float, default=0.5,\n",
    "                    help='learning rate decay factor for step decay')\n",
    "parser.add_argument('--optimizer', default='ADAM',\n",
    "                    choices=('SGD', 'ADAM', 'RMSprop'),\n",
    "                    help='optimizer to use (SGD | ADAM | RMSprop)')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--beta1', type=float, default=0.9,\n",
    "                    help='ADAM beta1')\n",
    "parser.add_argument('--beta2', type=float, default=0.999,\n",
    "                    help='ADAM beta2')\n",
    "parser.add_argument('--epsilon', type=float, default=1e-8,\n",
    "                    help='ADAM epsilon for numerical stability')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "\n",
    "# Loss specifications\n",
    "parser.add_argument('--loss', type=str, default='1*L1',\n",
    "                    help='loss function configuration')\n",
    "parser.add_argument('--skip_threshold', type=float, default='1e6',\n",
    "                    help='skipping batch that has large error')\n",
    "\n",
    "# Log specifications\n",
    "parser.add_argument('--save', type=str, default='My_RCAN',\n",
    "                    help='file name to save')\n",
    "parser.add_argument('--load', type=str, default='.',\n",
    "                    help='file name to load')\n",
    "parser.add_argument('--resume', type=int, default=0,\n",
    "                    help='resume from specific checkpoint')\n",
    "parser.add_argument('--print_model', action='store_true',\n",
    "                    help='print model')\n",
    "parser.add_argument('--save_models', action='store_true',\n",
    "                    help='save all intermediate models')\n",
    "parser.add_argument('--print_every', type=int, default=100,\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--save_results', action='store_true',\n",
    "                    help='save output results')\n",
    "\n",
    "# New options\n",
    "parser.add_argument('--n_resgroups', type=int, default=10,\n",
    "                    help='number of residual groups')\n",
    "parser.add_argument('--reduction', type=int, default=16,\n",
    "                    help='number of feature maps reduction')\n",
    "parser.add_argument('--testpath', type=str, default='../test/DIV2K_val_LR_our',\n",
    "                    help='dataset directory for testing')\n",
    "parser.add_argument('--testset', type=str, default='Set5',\n",
    "                    help='dataset name for testing')\n",
    "parser.add_argument('--degradation', type=str, default='BI',\n",
    "                    help='degradation model: BI, BD')\n",
    "\n",
    "# import platform \n",
    "# sys = platform.system()\n",
    "# if sys == \"Windows\":\n",
    "#     args = parser.parse_args(args=[])\n",
    "# else:\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "#     template.set_template(args)\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args.scale = list(map(lambda x: int(x), args.scale.split('+')))\n",
    "\n",
    "if args.epochs == 0:\n",
    "    args.epochs = 1e8\n",
    "\n",
    "for arg in vars(args):\n",
    "    if vars(args)[arg] == 'True':\n",
    "        vars(args)[arg] = True\n",
    "    elif vars(args)[arg] == 'False':\n",
    "        vars(args)[arg] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# args=set_args()\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "# from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v4\n",
    "from torch.utils.data import Dataset,random_split\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "from model import my_model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "accesss-s1 mean (0.4690)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = utility.checkpoint(args)\n",
    "net = model.Model(args, checkpoint)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# pre_train_path=\"./model/prprpr/best.pth\"\n",
    "# pre_train_path=\"test.pth\"\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_checkpoint = torch.load(pre_train_path,map_location=device)\n",
    "# net.load_state_dict(model_checkpoint[\"model\"])\n",
    "#         net.load(pre_train_path)\n",
    "# optimizer.load_state_dict(model_checkpoint['optimizer'])\n",
    "# epoch = model_checkpoint['epoch']\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9,last_epoch=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 79, 94)\n",
      "(316, 376)\n"
     ]
    }
   ],
   "source": [
    "#demo input precipitation data(pr)\n",
    "def prepare( l, volatile=False):\n",
    "    def _prepare(tensor):\n",
    "        if args.precision == 'half': tensor = tensor.half()\n",
    "        if args.precision == 'single': tensor = tensor.float()\n",
    "        return tensor.to(device)\n",
    "\n",
    "    return [_prepare(_l) for _l in l]\n",
    "import xarray as xr\n",
    "\n",
    "def add_lat_lon_data(data,domain=[112.9, 154.00, -43.7425, -9.0],xarray=True):\n",
    "    \"data: is the something you want to add lat and lon, with first demenstion is lat,second dimention is lon,domain is DEM domain \"\n",
    "    new_lon=np.linspace(domain[0],domain[1],data.shape[1])\n",
    "    new_lat=np.linspace(domain[2],domain[3],data.shape[0])\n",
    "    if xarray:\n",
    "        return xr.DataArray(data,coords=[new_lat,new_lon],dims=[\"lat\",\"lon\"])\n",
    "    else:\n",
    "        return data,new_lat,new_lon\n",
    "    \n",
    "demo_date=date(1990,1,25)\n",
    "idx=0\n",
    "ensamble_demo=\"e01\"\n",
    "# filename=file_ACCESS_dir+'pr/daily/'+ensamble_demo+\"/da_pr_\"+demo_date.strftime(\"%Y%m%d\")+\"_\"+ensamble_demo+\".nc\"\n",
    "# filename=\"/da_pr_\"+demo_date.strftime(\"%Y%m%d\")+\"_\"+ensamble_demo+\".nc\"\n",
    "file=\"../data/\"\n",
    "pr=np.expand_dims(np.repeat(np.expand_dims(dpt.read_access_data(file,ensamble_demo,demo_date,idx),axis=0),3,axis=0),axis=0)\n",
    "print(pr.shape)\n",
    "# zg=dpt.read_access_data(file,ensamble_demo,demo_date,idx,'zg')\n",
    "# tasmax=dpt.read_access_data(file,ensamble_demo,demo_date,idx,'tasmax')\n",
    "pr=prepare([torch.tensor(pr)])\n",
    "# print(pr)\n",
    "hr=net(pr[0],0).cpu().detach().numpy()\n",
    "print(np.squeeze(hr[:,1]).shape)\n",
    "\n",
    "\n",
    "title=\"test \\n date: \"+(demo_date+timedelta(idx)).strftime(\"%Y%m%d\")\n",
    "# prec_in=dpt.read_access_data(filename,idx=idx)*86400\n",
    "hr,lat,lon=add_lat_lon_data(np.squeeze(hr[:,1]),xarray=False)\n",
    "# print(hr)\n",
    "dpt.draw_aus(hr,lat,lon,title=title,save=True,path=\"test\")\n",
    "# print(prec_in.shape[0],prec_in.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "accesss-s1 mean (0.4690)\n",
      "load last train from./model/prprpr/best.pth\n",
      "{'gamma': 0.9, 'base_lrs': [1e-05], 'last_epoch': 21, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [1.197251518256203e-07]}\n",
      "(1, 3, 79, 94)\n",
      "(316, 376)\n",
      "Let's use1GPUs!\n"
     ]
    }
   ],
   "source": [
    "!python demo_result.py --n_resgroups 10 --n_resblocks 20 --patch_size 192 --prprpr --train_name \"prprpr\" --continue_train \"./model/prprpr/best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
