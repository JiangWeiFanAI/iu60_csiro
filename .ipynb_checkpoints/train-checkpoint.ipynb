{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--prprpr] [--debug] [--template TEMPLATE]\n",
      "                             [--n_threads N_THREADS] [--cpu] [--n_GPUs N_GPUS]\n",
      "                             [--seed SEED] [--pr PR] [--dem] [--psl] [--zg]\n",
      "                             [--tasmax] [--tasmin]\n",
      "                             [--leading_time_we_use LEADING_TIME_WE_USE]\n",
      "                             [--ensemble ENSEMBLE] [--channels CHANNELS]\n",
      "                             [--domain DOMAIN]\n",
      "                             [--file_ACCESS_dir FILE_ACCESS_DIR]\n",
      "                             [--file_BARRA_dir FILE_BARRA_DIR]\n",
      "                             [--file_DEM_dir FILE_DEM_DIR]\n",
      "                             [--nine2nine NINE2NINE]\n",
      "                             [--date_minus_one DATE_MINUS_ONE]\n",
      "                             [--dir_demo DIR_DEMO] [--benchmark_noise]\n",
      "                             [--n_train N_TRAIN] [--n_val N_VAL]\n",
      "                             [--offset_val OFFSET_VAL] [--ext EXT]\n",
      "                             [--scale SCALE] [--patch_size PATCH_SIZE]\n",
      "                             [--rgb_range RGB_RANGE] [--n_colors N_COLORS]\n",
      "                             [--noise NOISE] [--chop] [--model MODEL]\n",
      "                             [--act ACT] [--continue CONTINUE]\n",
      "                             [--pre_train PRE_TRAIN] [--extend EXTEND]\n",
      "                             [--n_resblocks N_RESBLOCKS] [--n_feats N_FEATS]\n",
      "                             [--res_scale RES_SCALE] [--shift_mean SHIFT_MEAN]\n",
      "                             [--precision {single,half,double}]\n",
      "                             [--train_name TRAIN_NAME] [--reset]\n",
      "                             [--test_every TEST_EVERY] [--epochs EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--split_batch SPLIT_BATCH] [--self_ensemble]\n",
      "                             [--test_only] [--gan_k GAN_K] [--lr LR]\n",
      "                             [--lr_decay LR_DECAY] [--decay_type DECAY_TYPE]\n",
      "                             [--gamma GAMMA] [--optimizer {SGD,ADAM,RMSprop}]\n",
      "                             [--momentum MOMENTUM] [--beta1 BETA1]\n",
      "                             [--beta2 BETA2] [--epsilon EPSILON]\n",
      "                             [--weight_decay WEIGHT_DECAY] [--loss LOSS]\n",
      "                             [--skip_threshold SKIP_THRESHOLD] [--save SAVE]\n",
      "                             [--load LOAD] [--resume RESUME] [--print_model]\n",
      "                             [--save_models] [--print_every PRINT_EVERY]\n",
      "                             [--save_results] [--n_resgroups N_RESGROUPS]\n",
      "                             [--reduction REDUCTION] [--testpath TESTPATH]\n",
      "                             [--testset TESTSET] [--degradation DEGRADATION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Weifa\\AppData\\Roaming\\jupyter\\runtime\\kernel-6ca948b9-a940-4714-82a4-fc2877179230.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#pr dem chennel\n",
    "\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v2_0,ACCESS_BARRA_v2_1\n",
    "import torch\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "from model import my_model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def write_log(log):\n",
    "    print(log)\n",
    "    if not os.path.exists(\"./model/save/\"+args.train_name+\"/\"):\n",
    "        os.mkdir(\"./model/save/\"+args.train_name+\"/\")\n",
    "    my_log_file=open(\"./model/save/\"+args.train_name + '/train.txt', 'a')\n",
    "#     log=\"Train for batch %d,data loading time cost %f s\"%(batch,start-time.time())\n",
    "    my_log_file.write(log + '\\n')\n",
    "    my_log_file.close()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    pre_train_path=args.continue_train\n",
    "    \n",
    "    if args.continue_train:\n",
    "        print(13113212)\n",
    "    init_date=date(1970, 1, 1)\n",
    "    start_date=date(1990, 1, 2)\n",
    "    end_date=date(2011,12,25)\n",
    "#     end_date=date(2012,12,25) #if 929 is true we should substract 1 day    \n",
    "    sys = platform.system()\n",
    "    args.file_ACCESS_dir=\"../data/\"\n",
    "    args.file_BARRA_dir=\"../data/barra_aus/\"\n",
    "#     if sys == \"Windows\":\n",
    "#         init_date=date(1970, 1, 1)\n",
    "#         start_date=date(1990, 1, 2)\n",
    "#         end_date=date(1990,12,15) #if 929 is true we should substract 1 day   \n",
    "#         args.cpu=True\n",
    "# #         args.file_ACCESS_dir=\"E:/climate/access-s1/\"\n",
    "# #         args.file_BARRA_dir=\"C:/Users/JIA059/barra/\"\n",
    "#         args.file_DEM_dir=\"../DEM/\"\n",
    "#     else:\n",
    "#         args.file_ACCESS_dir_pr=\"/g/data/ub7/access-s1/hc/raw_model/atmos/pr/daily/\"\n",
    "#         args.file_ACCESS_dir=\"/g/data/ub7/access-s1/hc/raw_model/atmos/\"\n",
    "#         # training_name=\"temp01\"\n",
    "#         args.file_BARRA_dir=\"/g/data/ma05/BARRA_R/v1/forecast/spec/accum_prcp/\"\n",
    "\n",
    "    args.channels=0\n",
    "    if args.pr:\n",
    "        args.channels+=1\n",
    "    if args.zg:\n",
    "        args.channels+=1\n",
    "    if args.psl:\n",
    "        args.channels+=1\n",
    "    if args.tasmax:\n",
    "        args.channels+=1\n",
    "    if args.tasmin:\n",
    "        args.channels+=1\n",
    "    if args.dem:\n",
    "        args.channels+=1\n",
    "    pre_train_path=\"./model/save/\"+args.train_name+\"/last_\"+str(args.channels)+\".pth\"\n",
    "    leading_time=217\n",
    "    args.leading_time_we_use=1\n",
    "    args.ensemble=11\n",
    "\n",
    "\n",
    "    print(\"training statistics:\")\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  trainning name  |  %s\"%args.train_name)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  num of channels | %5d\"%args.channels)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  num of threads  | %5d\"%args.n_threads)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  batch_size     | %5d\"%args.batch_size)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  using cpu only | %5d\"%args.cpu)\n",
    "\n",
    "    ############################################################################################\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "    #     transforms.Resize(IMG_SIZE),\n",
    "    #     transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    #     transforms.RandomHorizontalFlip(),\n",
    "    #     transforms.RandomRotation(30),\n",
    "        transforms.ToTensor()\n",
    "    #     transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "    ])\n",
    "    data_set=0\n",
    "    if args.prprpr:\n",
    "        data_set=ACCESS_BARRA_v2_0(start_date,end_date,transform=train_transforms,args=args)\n",
    "    else:\n",
    "        data_set=ACCESS_BARRA_v2_1(start_date,end_date,transform=train_transforms,args=args)\n",
    "\n",
    "    train_data,val_data=random_split(data_set,[int(len(data_set)*0.8),len(data_set)-int(len(data_set)*0.8)])\n",
    "\n",
    "\n",
    "    print(\"Dataset statistics:\")\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  total | %5d\"%len(data_set))\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  train | %5d\"%len(train_data))\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  val   | %5d\"%len(val_data))\n",
    "\n",
    "    ###################################################################################set a the dataLoader\n",
    "    train_dataloders =DataLoader(train_data,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=True,\n",
    "                                num_workers=args.n_threads)\n",
    "    val_dataloders =DataLoader(val_data,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=True,\n",
    "                              num_workers=args.n_threads)\n",
    "    ##\n",
    "    def prepare( l, volatile=False):\n",
    "        def _prepare(tensor):\n",
    "            if args.precision == 'half': tensor = tensor.half()\n",
    "            if args.precision == 'single': tensor = tensor.float()\n",
    "            return tensor.to(device)\n",
    "\n",
    "        return [_prepare(_l) for _l in l]\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    checkpoint = utility.checkpoint(args)\n",
    "    net = model.Model(args, checkpoint)\n",
    "#     net.load(\"./model/RCAN_BIX4.pt\", pre_train=\"./model/RCAN_BIX4.pt\", resume=args.resume, cpu=True)\n",
    "    if not args.prprpr:\n",
    "        net=my_model.Modify_RCAN(net,args,checkpoint)\n",
    "\n",
    "#     net.load(\"./model/RCAN_BIX4.pt\", pre_train=\"./model/RCAN_BIX4.pt\", resume=args.resume, cpu=args.cpu)\n",
    "    \n",
    "    args.lr=0.00001\n",
    "#     criterion = nn.L1Loss()\n",
    "    criterion=nn.MSELoss()\n",
    "    optimizer_my = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9)\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer_my, step_size=7, gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9)\n",
    "    # torch.optim.lr_scheduler.MultiStepLR(optimizer_my, milestones=[20,80], gamma=0.1)\n",
    "    \n",
    "#     if args.resume==1:\n",
    "#         print(\"continue last train\")\n",
    "#         model_checkpoint = torch.load(pre_train_path,map_location=device)\n",
    "#     else:\n",
    "#         print(\"restart train\")\n",
    "#         model_checkpoint = torch.load(\"./model/save/\"+args.train_name+\"/first_\"+str(args.channels)+\".pth\",map_location=device)\n",
    "\n",
    "#     my_net.load_state_dict(model_checkpoint['model'])\n",
    "#     optimizer_my.load_state_dict(model_checkpoint['optimizer'])\n",
    "#     epoch = model_checkpoint['epoch']\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        write_log(\"!!!!!!!!!!!!!Let's use\"+str(torch.cuda.device_count())+\"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        net = nn.DataParallel(net,range(torch.cuda.device_count()))\n",
    "    else:\n",
    "        write_log(\"Let's use\"+str(torch.cuda.device_count())+\"GPUs!\")\n",
    "\n",
    "#     my_net = torch.nn.DataParallel(my_net)\n",
    "    net.to(device)\n",
    "    \n",
    "    ##########################################################################training\n",
    "\n",
    "    write_log(\"start\")\n",
    "    max_error=np.inf\n",
    "    for e in range(args.epochs):\n",
    "        #train\n",
    "        scheduler.step()\n",
    "        net.train()\n",
    "        loss=0\n",
    "        start=time.time()\n",
    "        for batch, (pr,hr,_,_) in enumerate(train_dataloders):\n",
    "#             write_log(\"Train for batch %d,data loading time cost %f s\"%(batch,start-time.time()))\n",
    "            start=time.time()\n",
    "            pr,hr= prepare([pr,hr])\n",
    "\n",
    "            optimizer_my.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                sr = net(pr,0)\n",
    "                running_loss =criterion(sr, hr)\n",
    "                running_loss.backward()\n",
    "                optimizer_my.step()\n",
    "                \n",
    "            loss+=running_loss.item() #.copy()?\n",
    "            if batch%10==0:\n",
    "                state = {'model': net.state_dict(), 'optimizer': optimizer_my.state_dict(), 'epoch': e}\n",
    "                torch.save(state, \"./model/save/temp01/last.pth\")\n",
    "                write_log(\"Train done,train time cost %f s,loss: %f\"%(start-time.time(),running_loss.item()  ))\n",
    "            start=time.time()\n",
    "\n",
    "        #validation\n",
    "        net.eval()\n",
    "        start=time.time()\n",
    "        with torch.no_grad():\n",
    "            eval_psnr=0\n",
    "            eval_ssim=0\n",
    "#             tqdm_val = tqdm(val_dataloders, ncols=80)\n",
    "            for idx_img, (lr,hr,_,_) in enumerate(val_dataloders):\n",
    "                lr,hr = prepare([lr, hr])\n",
    "                sr = net(lr,0)\n",
    "                val_loss=criterion(sr, hr)\n",
    "                for ssr,hhr in zip(sr,hr):\n",
    "                    eval_psnr+=compare_psnr(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "                    write_log(str(eval_psnr))\n",
    "                    eval_ssim+=compare_ssim(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "                    write_log(str(eval_ssim))\n",
    "\n",
    "\n",
    "        write_log(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss:%f \"%(\n",
    "                  e,\n",
    "                  time.time()-start,\n",
    "                  optimizer_my.state_dict()['param_groups'][0]['lr'],\n",
    "                  loss/len(train_data),\n",
    "                  val_loss\n",
    "             ))\n",
    "#         print(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss:%f \"%(\n",
    "#                   e,\n",
    "#                   time.time()-start,\n",
    "#                   optimizer_my.state_dict()['param_groups'][0]['lr'],\n",
    "#                   loss.item()/len(train_data),\n",
    "#                   val_loss\n",
    "#              ))\n",
    "\n",
    "        if loss<max_error:\n",
    "            max_error=loss\n",
    "    #         torch.save(net,train_loss\"_\"+str(e)+\".pkl\")\n",
    "            if not os.path.exists(\"./model/save/\"+args.train_name+\"/\"):\n",
    "                os.mkdir(\"./model/save/\"+args.train_name+\"/\")\n",
    "            write_log(\"saving\")\n",
    "            state = {'model': net.state_dict(), 'optimizer': optimizer_my.state_dict(), 'epoch': e}\n",
    "            torch.save(state, \"./model/save/temp01/\"+str(e)+\"_best.pth\")\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--args_test ARGS_TEST] [--debug]\n",
      "                             [--template TEMPLATE] [--n_threads N_THREADS]\n",
      "                             [--cpu] [--n_GPUs N_GPUS] [--seed SEED] [--pr PR]\n",
      "                             [--dem] [--psl] [--zg] [--tasmax] [--tasmin]\n",
      "                             [--leading_time_we_use LEADING_TIME_WE_USE]\n",
      "                             [--ensemble ENSEMBLE] [--channels CHANNELS]\n",
      "                             [--domain DOMAIN]\n",
      "                             [--file_ACCESS_dir FILE_ACCESS_DIR]\n",
      "                             [--file_BARRA_dir FILE_BARRA_DIR]\n",
      "                             [--file_DEM_dir FILE_DEM_DIR]\n",
      "                             [--nine2nine NINE2NINE]\n",
      "                             [--date_minus_one DATE_MINUS_ONE]\n",
      "                             [--dir_demo DIR_DEMO] [--benchmark_noise]\n",
      "                             [--n_train N_TRAIN] [--n_val N_VAL]\n",
      "                             [--offset_val OFFSET_VAL] [--ext EXT]\n",
      "                             [--scale SCALE] [--patch_size PATCH_SIZE]\n",
      "                             [--rgb_range RGB_RANGE] [--n_colors N_COLORS]\n",
      "                             [--noise NOISE] [--chop] [--model MODEL]\n",
      "                             [--act ACT] [--pre_train PRE_TRAIN]\n",
      "                             [--extend EXTEND] [--n_resblocks N_RESBLOCKS]\n",
      "                             [--n_feats N_FEATS] [--res_scale RES_SCALE]\n",
      "                             [--shift_mean SHIFT_MEAN]\n",
      "                             [--precision {single,half,double}]\n",
      "                             [--train_name TRAIN_NAME] [--reset]\n",
      "                             [--test_every TEST_EVERY] [--epochs EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--split_batch SPLIT_BATCH] [--self_ensemble]\n",
      "                             [--test_only] [--gan_k GAN_K] [--lr LR]\n",
      "                             [--lr_decay LR_DECAY] [--decay_type DECAY_TYPE]\n",
      "                             [--gamma GAMMA] [--optimizer {SGD,ADAM,RMSprop}]\n",
      "                             [--momentum MOMENTUM] [--beta1 BETA1]\n",
      "                             [--beta2 BETA2] [--epsilon EPSILON]\n",
      "                             [--weight_decay WEIGHT_DECAY] [--loss LOSS]\n",
      "                             [--skip_threshold SKIP_THRESHOLD] [--save SAVE]\n",
      "                             [--load LOAD] [--resume RESUME] [--print_model]\n",
      "                             [--save_models] [--print_every PRINT_EVERY]\n",
      "                             [--save_results] [--n_resgroups N_RESGROUPS]\n",
      "                             [--reduction REDUCTION] [--testpath TESTPATH]\n",
      "                             [--testset TESTSET] [--degradation DEGRADATION]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Weifa\\AppData\\Roaming\\jupyter\\runtime\\kernel-6ca948b9-a940-4714-82a4-fc2877179230.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#pr dem chennel\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v2_0,ACCESS_BARRA_v2_1\n",
    "import torch\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "from model import my_model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def write_log(log):\n",
    "    print(log)\n",
    "    my_log_file=open(\"./model/save/\"+args.train_name + '/train.txt', 'a')\n",
    "#     log=\"Train for batch %d,data loading time cost %f s\"%(batch,start-time.time())\n",
    "    my_log_file.write(log + '\\n')\n",
    "    my_log_file.close()\n",
    "    return\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "#     pre_train_path=\"./model/save/temp01/\"+0+\".pth\"\n",
    "\n",
    "    \n",
    "    \n",
    "    init_date=date(1970, 1, 1)\n",
    "    start_date=date(1990, 1, 2)\n",
    "    end_date=date(2011,12,25)\n",
    "#     end_date=date(2012,12,25) #if 929 is true we should substract 1 day    \n",
    "    sys = platform.system()\n",
    "    args.file_ACCESS_dir=\"../data/\"\n",
    "    args.file_BARRA_dir=\"../data/barra_aus/\"\n",
    "#     if sys == \"Windows\":\n",
    "#         init_date=date(1970, 1, 1)\n",
    "#         start_date=date(1990, 1, 2)\n",
    "#         end_date=date(1990,12,15) #if 929 is true we should substract 1 day   \n",
    "#         args.cpu=True\n",
    "# #         args.file_ACCESS_dir=\"E:/climate/access-s1/\"\n",
    "# #         args.file_BARRA_dir=\"C:/Users/JIA059/barra/\"\n",
    "#         args.file_DEM_dir=\"../DEM/\"\n",
    "#     else:\n",
    "#         args.file_ACCESS_dir_pr=\"/g/data/ub7/access-s1/hc/raw_model/atmos/pr/daily/\"\n",
    "#         args.file_ACCESS_dir=\"/g/data/ub7/access-s1/hc/raw_model/atmos/\"\n",
    "#         # training_name=\"temp01\"\n",
    "#         args.file_BARRA_dir=\"/g/data/ma05/BARRA_R/v1/forecast/spec/accum_prcp/\"\n",
    "\n",
    "    args.channels=0\n",
    "    if args.pr:\n",
    "        args.channels+=1\n",
    "    if args.zg:\n",
    "        args.channels+=1\n",
    "    if args.psl:\n",
    "        args.channels+=1\n",
    "    if args.tasmax:\n",
    "        args.channels+=1\n",
    "    if args.tasmin:\n",
    "        args.channels+=1\n",
    "    if args.dem:\n",
    "        args.channels+=1\n",
    "    access_rgb_mean= 2.9067910245780248e-05*86400\n",
    "    pre_train_path=\"./model/save/\"+args.train_name+\"/last_\"+str(args.channels)+\".pth\"\n",
    "    leading_time=217\n",
    "    args.leading_time_we_use=1\n",
    "    args.ensemble=1\n",
    "\n",
    "\n",
    "    print(access_rgb_mean)\n",
    "\n",
    "    print(\"training statistics:\")\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  trainning name  |  %s\"%args.train_name)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  num of channels | %5d\"%args.channels)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  num of threads  | %5d\"%args.n_threads)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  batch_size     | %5d\"%args.batch_size)\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  using cpu only？ | %5d\"%args.cpu)\n",
    "\n",
    "    ############################################################################################\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "    #     transforms.Resize(IMG_SIZE),\n",
    "    #     transforms.RandomResizedCrop(IMG_SIZE),\n",
    "    #     transforms.RandomHorizontalFlip(),\n",
    "    #     transforms.RandomRotation(30),\n",
    "        transforms.ToTensor()\n",
    "    #     transforms.Normalize(IMG_MEAN, IMG_STD)\n",
    "    ])\n",
    "\n",
    "#     data_set=ACCESS_BARRA_v2_0(start_date,end_date,transform=train_transforms,args=args)\n",
    "    data_set=ACCESS_BARRA_v2_1(start_date,end_date,transform=train_transforms,args=args)\n",
    "\n",
    "    train_data,val_data=random_split(data_set,[int(len(data_set)*0.8),len(data_set)-int(len(data_set)*0.8)])\n",
    "\n",
    "\n",
    "    print(\"Dataset statistics:\")\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  total | %5d\"%len(data_set))\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  train | %5d\"%len(train_data))\n",
    "    print(\"  ------------------------------\")\n",
    "    print(\"  val   | %5d\"%len(val_data))\n",
    "\n",
    "    ###################################################################################set a the dataLoader\n",
    "    train_dataloders =DataLoader(train_data,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=True,\n",
    "                                num_workers=args.n_threads)\n",
    "    val_dataloders =DataLoader(val_data,\n",
    "                                            batch_size=args.batch_size,\n",
    "                                            shuffle=True,\n",
    "                              num_workers=args.n_threads)\n",
    "    ##\n",
    "    def prepare( l, volatile=False):\n",
    "        def _prepare(tensor):\n",
    "            if args.precision == 'half': tensor = tensor.half()\n",
    "            if args.precision == 'single': tensor = tensor.float()\n",
    "            return tensor.to(device)\n",
    "\n",
    "        return [_prepare(_l) for _l in l]\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    checkpoint = utility.checkpoint(args)\n",
    "    net = model.Model(args, checkpoint)\n",
    "#     net.load(\"./model/RCAN_BIX4.pt\", pre_train=\"./model/RCAN_BIX4.pt\", resume=args.resume, cpu=True)\n",
    "    net=my_model.Modify_RCAN(net,args,checkpoint)\n",
    "\n",
    "#     net.load(\"./model/RCAN_BIX4.pt\", pre_train=\"./model/RCAN_BIX4.pt\", resume=args.resume, cpu=args.cpu)\n",
    "    \n",
    "    args.lr=0.00001\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer_my = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9)\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer_my, step_size=7, gamma=0.1)\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9)\n",
    "    # torch.optim.lr_scheduler.MultiStepLR(optimizer_my, milestones=[20,80], gamma=0.1)\n",
    "    \n",
    "#     if args.resume==1:\n",
    "#         print(\"continue last train\")\n",
    "#         model_checkpoint = torch.load(pre_train_path,map_location=device)\n",
    "#     else:\n",
    "#         print(\"restart train\")\n",
    "#         model_checkpoint = torch.load(\"./model/save/\"+args.train_name+\"/first_\"+str(args.channels)+\".pth\",map_location=device)\n",
    "\n",
    "#     my_net.load_state_dict(model_checkpoint['model'])\n",
    "#     optimizer_my.load_state_dict(model_checkpoint['optimizer'])\n",
    "#     epoch = model_checkpoint['epoch']\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        write_log(\"Let's use\"+str(torch.cuda.device_count())+\"GPUs!\")\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        net = nn.DataParallel(net)\n",
    "    else:\n",
    "        write_log(\"Let's use\"+str(torch.cuda.device_count())+\"GPUs!\")\n",
    "\n",
    "#     my_net = torch.nn.DataParallel(my_net)\n",
    "    net.to(device)\n",
    "    \n",
    "    ##########################################################################training\n",
    "\n",
    "    write_log(\"start\")\n",
    "    max_error=np.inf\n",
    "    for e in range(args.epochs):\n",
    "        #train\n",
    "        scheduler.step()\n",
    "        net.train()\n",
    "        loss=0\n",
    "        start=time.time()\n",
    "        for batch, (pr,dem,hr,_,_) in enumerate(train_dataloders):\n",
    "            write_log(\"Train for batch %d,data loading time cost %f s\"%(batch,start-time.time()))\n",
    "            start=time.time()\n",
    "            pr,dem,hr= prepare([pr,dem,hr])\n",
    "\n",
    "            optimizer_my.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                sr = net(pr,dem,0)\n",
    "                running_loss =criterion(sr, hr)\n",
    "                running_loss.backward()\n",
    "                optimizer_my.step()\n",
    "                \n",
    "            loss+=running_loss #.copy()?\n",
    "            if batch%10==0:\n",
    "                state = {'model': net.state_dict(), 'optimizer': optimizer_my.state_dict(), 'epoch': e}\n",
    "                torch.save(state, \"./model/save/temp01/last.pth\")\n",
    "            write_log(\"Train done,train time cost %f s,loss: %f\"%(start-time.time(),running_loss.item()  ))\n",
    "            start=time.time()\n",
    "\n",
    "        #validation\n",
    "        net.eval()\n",
    "        start=time.time()\n",
    "        with torch.no_grad():\n",
    "            eval_psnr=0\n",
    "            eval_ssim=0\n",
    "#             tqdm_val = tqdm(val_dataloders, ncols=80)\n",
    "            for idx_img, (lr,dem,hr,_,_) in enumerate(val_dataloders):\n",
    "                lr,dem,hr = prepare([lr,dem,hr])\n",
    "                sr = net(lr,dem,0)\n",
    "                val_loss=criterion(sr, hr)\n",
    "                for ssr,hhr in zip(sr,hr):\n",
    "                    eval_psnr+=compare_psnr(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "                    eval_ssim+=compare_ssim(ssr[0].cpu().numpy(),hhr[0].cpu().numpy(),data_range=(hhr[0].cpu().max()-hhr[0].cpu().min()).item() )\n",
    "\n",
    "        write_log(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss:%f \"%(\n",
    "                  e,\n",
    "                  time.time()-start,\n",
    "                  optimizer_my.state_dict()['param_groups'][0]['lr'],\n",
    "                  loss.item()/len(train_data),\n",
    "                  val_loss\n",
    "             ))\n",
    "#         print(\"epoche: %d,time cost %f s, lr: %f, train_loss: %f,validation loss:%f \"%(\n",
    "#                   e,\n",
    "#                   time.time()-start,\n",
    "#                   optimizer_my.state_dict()['param_groups'][0]['lr'],\n",
    "#                   loss.item()/len(train_data),\n",
    "#                   val_loss\n",
    "#              ))\n",
    "\n",
    "        if running_loss<max_error:\n",
    "            max_error=running_loss\n",
    "    #         torch.save(net,train_loss\"_\"+str(e)+\".pkl\")\n",
    "            if not os.path.exists(\"./model/save/\"+args.train_name+\"/\"):\n",
    "                os.mkdir(\"./model/save/\"+args.train_name+\"/\")\n",
    "            write_log(\"saving\")\n",
    "            state = {'model': net.state_dict(), 'optimizer': optimizer_my.state_dict(), 'epoch': e}\n",
    "            torch.save(state, \"./model/save/temp01/\"+str(e)+\".pth\")\n",
    "            \n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr dem chennel\n",
    "import os\n",
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "# from args_parameter import args\n",
    "from PrepareData import ACCESS_BARRA_v2_0,ACCESS_BARRA_v2_1\n",
    "import torch\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from PIL import Image\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import model\n",
    "from model import my_model\n",
    "import utility\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xarray as xr\n",
    "from skimage.measure import compare_ssim\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "import platform\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.09000000000000001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 1, '_step_count': 2, '_get_lr_called_within_step': False, '_last_lr': [0.09000000000000001]}\n",
      "{'lr': 0.08100000000000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 2, '_step_count': 3, '_get_lr_called_within_step': False, '_last_lr': [0.08100000000000002]}\n",
      "{'lr': 0.07290000000000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 3, '_step_count': 4, '_get_lr_called_within_step': False, '_last_lr': [0.07290000000000002]}\n",
      "{'lr': 0.06561000000000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 4, '_step_count': 5, '_get_lr_called_within_step': False, '_last_lr': [0.06561000000000002]}\n",
      "{'lr': 0.05904900000000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 5, '_step_count': 6, '_get_lr_called_within_step': False, '_last_lr': [0.05904900000000002]}\n",
      "{'lr': 0.05314410000000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 6, '_step_count': 7, '_get_lr_called_within_step': False, '_last_lr': [0.05314410000000002]}\n",
      "{'lr': 0.04782969000000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 7, '_step_count': 8, '_get_lr_called_within_step': False, '_last_lr': [0.04782969000000002]}\n",
      "{'lr': 0.043046721000000024, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 8, '_step_count': 9, '_get_lr_called_within_step': False, '_last_lr': [0.043046721000000024]}\n",
      "{'lr': 0.03874204890000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 9, '_step_count': 10, '_get_lr_called_within_step': False, '_last_lr': [0.03874204890000002]}\n",
      "{'lr': 0.03486784401000002, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'initial_lr': 0.1, 'params': [1883590614056, 1883589619864, 1883589619944, 1883589121032, 1883589120712, 1883589120392, 1883590971128, 1883588954936, 1883588954456, 1883632159304, 1883588157752, 1883591210552, 1883631773800, 1883585893704, 1883585893224, 1883631930088, 1883631928008, 1883631929608, 1883631931208, 1883631931288, 1883631930408, 1883631927688, 1883629278456, 1883629278856, 1883590984552, 1883590752440, 1883590750760, 1883590752520, 1883591241224, 1883591238264, 1883591413336, 1883591411176, 1883591410296, 1883591413576, 1883591412936, 1883591410696, 1883589142872, 1883591342024, 1883591341144, 1883591342424, 1883591340744, 1883591343624, 1883591091848, 1883588148904, 1883591092328, 1883591094168, 1883591093768, 1883591091128, 1883591093368, 1883591092488, 1883591090808, 1883591090488, 1883590671400, 1883590669320, 1883591324280, 1883591325560, 1883591326840, 1883591327560, 1883590805048, 1883590803688, 1883591002536, 1883591000616, 1883591001096, 1883591257208, 1883591256648, 1883590716136, 1883590715416, 1883590714776, 1883590714376, 1883590717336, 1883590713976, 1883590714856, 1883590714616, 1883590715096, 1883590716296, 1883591182360, 1883591182600, 1883591181320, 1883591183160, 1883591183640, 1883591183320, 1883591183720, 1883591150952, 1883591147832, 1883591151032, 1883591148712, 1883591148952, 1883591149352, 1883591149672, 1883591149432, 1883591151112, 1883631761912, 1883631761752, 1883631762072, 1883631762312, 1883631759912, 1883631762392, 1883631760632, 1883631759752, 1883590875880, 1883590876040, 1883590874760, 1883590873320, 1883590873960, 1883590898856, 1883590898696, 1883590901256, 1883590900456, 1883590913624, 1883590913464, 1883590911224, 1883590913784, 1883590930248, 1883590928328, 1883590929608, 1883590926648, 1883590928008, 1883590927448, 1883590950408, 1883590949928, 1883590948248, 1883590949528, 1883590950808, 1883590949208, 1883590950168, 1883590948008, 1883591374872, 1883591040200, 1883591040840, 1883588910200, 1883590683608, 1883590682488, 1883588851096, 1883590776456, 1883590775496, 1883590775416, 1883590863912, 1883590861672, 1883591625288, 1883591626088, 1883591624488, 1883591625368, 1883591625608, 1883591626008, 1883591124456, 1883591124056, 1883591125256, 1883592540312, 1883592542872, 1883592541992, 1883592543912, 1883592466984, 1883592468344, 1883592467304, 1883592467544, 1883592467064, 1883591433896, 1883591432936]}\n",
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 10, '_step_count': 11, '_get_lr_called_within_step': False, '_last_lr': [0.03486784401000002]}\n"
     ]
    }
   ],
   "source": [
    "net=models.mnasnet0_75()\n",
    "optimizer_my = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9)\n",
    "for e in range(10):\n",
    "    scheduler.step()\n",
    "    print(optimizer_my.state_dict()['param_groups'][0])\n",
    "    print(scheduler.state_dict())\n",
    "state = {'model': net.state_dict(), 'optimizer': optimizer_my.state_dict(), 'epoch': e}\n",
    "torch.save(state, \"test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = torch.load(\"test.pth\")\n",
    "optimizer_my.load_state_dict(model_checkpoint['optimizer'])\n",
    "epoch = model_checkpoint['epoch']\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_my, gamma=0.9,last_epoch=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.9, 'base_lrs': [0.1], 'last_epoch': 100, '_step_count': 1, '_get_lr_called_within_step': False, '_last_lr': [2.3905258998828797e-06]}\n"
     ]
    }
   ],
   "source": [
    "print(scheduler.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model/save/123\"):\n",
    "    os.mkdir(\"./model/save/123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316, 376, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "import numpy as np\n",
    "np.repeat(np.expand_dims(dpt.read_barra_data_fc(\"../data/barra_aus/\",datetime(1990,1,2)),axis=2),3,axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5114674452354135\n",
      "training statistics:\n",
      "  ------------------------------\n",
      "  trainning name  |  temp01\n",
      "  ------------------------------\n",
      "  num of channels |     1\n",
      "  ------------------------------\n",
      "  num of threads  |     0\n",
      "  ------------------------------\n",
      "  batch_size     |     2\n",
      "  ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 256, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 101, in main\n",
      "    print(\"  using cpu only\\uff1f | %5d\"%args.cpu)\n",
      "  File \"E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\uff1f' in position 16: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "python train_pr.py  --n_threads 0  --batch_size 2 --n_resgroups 10 --n_resblocks 20 --patch_size 192 --pre_train \"./model/RCAN_BIX4.pt\"\n",
    "python train_pr_dem.py  --n_threads 0  --batch_size 2 --n_resgroups 10 --n_resblocks 20 --patch_size 192 --train_name \"pr_dem\" --dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
